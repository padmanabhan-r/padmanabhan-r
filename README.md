### ğŸ‘‹ hi anon, iâ€™m padmanabhan

i build systems that listen, react, and adapt.

---

### ğŸ§ª what iâ€™m usually tinkering with

- real-time feedback systems (audio, sensors, edge devices)
- agentic and RAG workflow ideas
- edge AI experiments on raspberry pi, mics, cameras, and whateverâ€™s lying around

---

### ğŸ¸ fretcoach (current rabbit hole)

*this section changes as i move from one rabbit hole to the next.*

**fretcoach** is an AI-powered guitar practice system.  
it listens while you play and intervenes immediately.

- on-device audio analysis
- ai coaching and reflection
- edge hardware + cloud backend
- feedback via screen, voice, and ambient light

> most tools tell you what you did wrong.  
> **this stops you from doing it again.**

---

### ğŸ§  tools i reach for

**ai / ml**
- llms, rag, agentic systems
- pytorch, tensorflow, scikit-learn
- hugging face, openai

**edge / backend**
- python, fastapi
- tensorflow lite, audio dsp, sensors

**infra**
- postgres, mongodb, bigquery
- kubernetes, openshift
- docker, terraform
- gcp

**ui**
- react, streamlit, gradio
- dashboards when i really have to

---

### ğŸµ outside the terminal

- guitar & drums (metal, prog, noise)
- if it runs on a pi, itâ€™s fair game

ğŸ”— https://padmanabhan-r.github.io  
ğŸ”— https://www.linkedin.com/in/padmanabhan-rajendrakumar/
